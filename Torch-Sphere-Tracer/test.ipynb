{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrenderers\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1544\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import renderers\n",
    "import sdf\n",
    "import csg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rotation_matrix(axes, angles):\n",
    "    nx, ny, nz = torch.unbind(axes, dim=-1)\n",
    "    c, s = torch.cos(angles), torch.sin(angles)\n",
    "    rotation_matrices = torch.stack([\n",
    "        torch.stack([nx * nx * (1.0 - c) + 1. * c, ny * nx * (1.0 - c) - nz * s, nz * nx * (1.0 - c) + ny * s], dim=-1),\n",
    "        torch.stack([nx * ny * (1.0 - c) + nz * s, ny * ny * (1.0 - c) + 1. * c, nz * ny * (1.0 - c) - nx * s], dim=-1),\n",
    "        torch.stack([nx * nz * (1.0 - c) - ny * s, ny * nz * (1.0 - c) + nx * s, nz * nz * (1.0 - c) + 1. * c], dim=-1),\n",
    "    ], dim=-2)\n",
    "    return rotation_matrices\n",
    "\n",
    "def render(signed_distance_function):\n",
    "    \n",
    "    # ---------------- camera matrix ---------------- #\n",
    "\n",
    "    fx = fy = 1024\n",
    "    cx = cy = 512\n",
    "    camera_matrix = torch.tensor([[fx, 0.0, cx], [0.0, fy, cy], [0.0, 0.0, 1.0]], device=device).float()\n",
    "\n",
    "    # ---------------- camera position ---------------- #\n",
    "\n",
    "    distance = 5.0\n",
    "    azimuth = np.pi / 4.0\n",
    "    elevation = np.pi / 4.0\n",
    "\n",
    "    camera_position = torch.tensor([\n",
    "        +np.cos(elevation) * np.sin(azimuth), \n",
    "        -np.sin(elevation), \n",
    "        -np.cos(elevation) * np.cos(azimuth)\n",
    "    ], device=device).float() * distance\n",
    "\n",
    "    # ---------------- camera rotation ---------------- #\n",
    "\n",
    "    target_position = torch.tensor([0.0, -1.0, 0.0], device=device).float()\n",
    "    up_direction = torch.tensor([0.0, 1.0, 0.0], device=device).float()\n",
    "\n",
    "    camera_z_axis = target_position - camera_position\n",
    "    camera_x_axis = torch.cross(up_direction, camera_z_axis, dim=-1)\n",
    "    camera_y_axis = torch.cross(camera_z_axis, camera_x_axis, dim=-1)\n",
    "    camera_rotation = torch.stack((camera_x_axis, camera_y_axis, camera_z_axis), dim=-1)\n",
    "    camera_rotation = nn.functional.normalize(camera_rotation, dim=-2)\n",
    "\n",
    "    # ---------------- directional light ---------------- #\n",
    "\n",
    "    light_directions = torch.tensor([1.0, -0.5, 0.0], device=device)\n",
    "\n",
    "    # ---------------- ray marching ---------------- #\n",
    "\n",
    "    y_positions = torch.arange(cy * 2, dtype=camera_matrix.dtype, device=device).float()\n",
    "    x_positions = torch.arange(cx * 2, dtype=camera_matrix.dtype, device=device).float()\n",
    "    y_positions, x_positions = torch.meshgrid(y_positions, x_positions, indexing='ij')\n",
    "    z_positions = torch.ones_like(y_positions).float()\n",
    "    ray_positions = torch.stack((x_positions, y_positions, z_positions), dim=-1)\n",
    "    ray_positions = torch.einsum(\"mn,...n->...m\", torch.inverse(camera_matrix),  ray_positions)\n",
    "    ray_positions = torch.einsum(\"mn,...n->...m\", camera_rotation, ray_positions) + camera_position\n",
    "    ray_directions = nn.functional.normalize(ray_positions - camera_position, dim=-1)\n",
    "   \n",
    "    # ---------------- rendering ---------------- #\n",
    "\n",
    "    ground = sdf.plane(torch.tensor([0.0, -1.0, 0.0], device=device), 0.0)\n",
    "        \n",
    "    num_iterations = 100\n",
    "    convergence_threshold = 1e-1\n",
    "    #signed_distance_function = csg.union(signed_distance_function, ground)\n",
    "    signed_distance_function = signed_distance_function\n",
    "\n",
    "    surface_positions, converged = renderers.sphere_tracing(\n",
    "                    signed_distance_function=signed_distance_function, \n",
    "                    ray_positions=ray_positions, \n",
    "                    ray_directions=ray_directions, \n",
    "                    num_iterations=num_iterations, \n",
    "                    convergence_threshold=convergence_threshold,\n",
    "                )\n",
    "    \n",
    "    surface_positions = torch.where(converged, surface_positions, torch.zeros_like(surface_positions))\n",
    "    \n",
    "    surface_normals = renderers.compute_normal(\n",
    "        signed_distance_function=signed_distance_function, \n",
    "        surface_positions=surface_positions,\n",
    "    )\n",
    "    surface_normals = torch.where(converged, surface_normals, torch.zeros_like(surface_normals))\n",
    "\n",
    "    image = renderers.phong_shading(\n",
    "        surface_normals=surface_normals, \n",
    "        view_directions=camera_position - surface_positions, \n",
    "        light_directions=light_directions, \n",
    "        light_ambient_color=torch.ones(1, 1, 3, device=device),\n",
    "        light_diffuse_color=torch.ones(1, 1, 3, device=device), \n",
    "        light_specular_color=torch.ones(1, 1, 3, device=device), \n",
    "        material_ambient_color=torch.full((1, 1, 3), 0.2, device=device) + (torch.rand(1, 1, 3, device=device) * 2 - 1) * 0.1,\n",
    "        material_diffuse_color=torch.full((1, 1, 3), 0.7, device=device) + (torch.rand(1, 1, 3, device=device) * 2 - 1) * 0.1,\n",
    "        material_specular_color=torch.full((1, 1, 3), 0.1, device=device),\n",
    "        material_emission_color=torch.zeros(1, 1, 3, device=device),\n",
    "        material_shininess=64.0,\n",
    "    )\n",
    "\n",
    "    grounded = torch.abs(ground(surface_positions)) < convergence_threshold\n",
    "    image = torch.where(grounded, torch.full_like(image, 0.9), image)\n",
    "\n",
    "    shadowed = renderers.compute_shadows(\n",
    "        signed_distance_function=signed_distance_function, \n",
    "        surface_positions=surface_positions, \n",
    "        surface_normals=surface_normals,\n",
    "        light_directions=light_directions, \n",
    "        num_iterations=num_iterations, \n",
    "        convergence_threshold=convergence_threshold,\n",
    "        foreground_masks=converged,\n",
    "    )\n",
    "    image = torch.where(shadowed, image * 0.5, image)\n",
    "\n",
    "    image = torch.where(converged, image, torch.ones_like(image))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- load target ---------------- #\n",
    "from pytorch3d.io import load_ply\n",
    "from pytorch3d.structures import Meshes\n",
    "import meshplot as mp\n",
    "\n",
    "def load_target(path):\n",
    "    # Load the target mesh\n",
    "    verts, faces = load_ply(path)\n",
    "\n",
    "    # Convert vertices to a tensor if not already\n",
    "    if not isinstance(verts, torch.Tensor):\n",
    "        verts = torch.tensor(verts, dtype=torch.float32)\n",
    "\n",
    "    # Step 1: Compute the bounding box (min/max coordinates)\n",
    "    min_coords = verts.min(dim=0)[0]\n",
    "    max_coords = verts.max(dim=0)[0]\n",
    "\n",
    "    # Step 2: Compute the center of the bounding box\n",
    "    center = (min_coords + max_coords) / 2.0\n",
    "\n",
    "    # Step 3: Center the object to the origin\n",
    "    verts_centered = verts - center\n",
    "\n",
    "    # Step 4: Compute the scale factor to fit within the unit cube\n",
    "    scale_factor = 1.0 / (max_coords - min_coords).max()\n",
    "\n",
    "    # Step 5: Scale the object to fit the unit cube\n",
    "    verts_scaled = verts_centered * scale_factor\n",
    "\n",
    "    # Step 6: Translate the object to the first octant (shift so all coordinates are positive)\n",
    "    #min_coords_after_scaling = verts_scaled.min(dim=0)[0]\n",
    "    #verts_final = verts_scaled - min_coords_after_scaling\n",
    "\n",
    "    # Now `mesh` is centered and scaled to fit in the first octant cube\n",
    "    return verts_scaled, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.ops import knn_points\n",
    "\n",
    "def multi_indexing(index: torch.Tensor, shape: torch.Size, dim=-2):\n",
    "    shape = list(shape)\n",
    "    back_pad = len(shape) - index.ndim\n",
    "    for _ in range(back_pad):\n",
    "        index = index.unsqueeze(-1)\n",
    "    expand_shape = shape\n",
    "    expand_shape[dim] = -1\n",
    "    return index.expand(*expand_shape)\n",
    "\n",
    "\n",
    "def multi_gather(values: torch.Tensor, index: torch.Tensor, dim=-2):\n",
    "    # take care of batch dimension of, and acts like a linear indexing in the target dimention\n",
    "    # we assume that the index's last dimension is the dimension to be indexed on\n",
    "    return values.gather(dim, multi_indexing(index, values.shape, dim))\n",
    "\n",
    "\n",
    "def winding_number(pts: torch.Tensor, verts: torch.Tensor, faces: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Parallel implementation of the Generalized Winding Number of points on the mesh\n",
    "    O(n_points * n_faces) memory usage, parallelized execution\n",
    "\n",
    "    1. Project tris onto the unit sphere around every points\n",
    "    2. Compute the signed solid angle of the each triangle for each point\n",
    "    3. Sum the solid angle of each triangle\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pts    : torch.Tensor, (n_points, 3)\n",
    "    verts  : torch.Tensor, (n_verts, 3)\n",
    "    faces  : torch.Tensor, (n_faces, 3)\n",
    "\n",
    "    This implementation is also able to take a/multiple batch dimension\n",
    "    \"\"\"\n",
    "    # projection onto unit sphere: verts implementation gives a little bit more performance\n",
    "    uv = verts[..., None, :, :] - pts[..., :, None, :]  # n_points, n_verts, 3\n",
    "    uv = uv / uv.norm(dim=-1, keepdim=True)  # n_points, n_verts, 3\n",
    "\n",
    "    # gather from the computed vertices (will result in a copy for sure)\n",
    "    expanded_faces = faces[..., None, :, :].expand(*faces.shape[:-2], pts.shape[-2], *faces.shape[-2:])  # n_points, n_faces, 3\n",
    "\n",
    "    u0 = multi_gather(uv, expanded_faces[..., 0])  # n, f, 3\n",
    "    u1 = multi_gather(uv, expanded_faces[..., 1])  # n, f, 3\n",
    "    u2 = multi_gather(uv, expanded_faces[..., 2])  # n, f, 3\n",
    "\n",
    "    e0 = u1 - u0  # n, f, 3\n",
    "    e1 = u2 - u1  # n, f, 3\n",
    "    del u1\n",
    "\n",
    "    # compute solid angle signs\n",
    "    sign = (torch.cross(e0, e1, dim=-1) * u2).sum(dim=-1).sign()\n",
    "\n",
    "    e2 = u0 - u2\n",
    "    del u0, u2\n",
    "\n",
    "    l0 = e0.norm(dim=-1)\n",
    "    del e0\n",
    "\n",
    "    l1 = e1.norm(dim=-1)\n",
    "    del e1\n",
    "\n",
    "    l2 = e2.norm(dim=-1)\n",
    "    del e2\n",
    "\n",
    "    # compute edge lengths: pure triangle\n",
    "    l = torch.stack([l0, l1, l2], dim=-1)  # n_points, n_faces, 3\n",
    "\n",
    "    # compute spherical edge lengths\n",
    "    l = 2 * (l/2).arcsin()  # n_points, n_faces, 3\n",
    "\n",
    "    # compute solid angle: preparing: n_points, n_faces\n",
    "    s = l.sum(dim=-1) / 2\n",
    "    s0 = s - l[..., 0]\n",
    "    s1 = s - l[..., 1]\n",
    "    s2 = s - l[..., 2]\n",
    "\n",
    "    # compute solid angle: and generalized winding number: n_points, n_faces\n",
    "    eps = 1e-10  # NOTE: will cause nan if not bigger than 1e-10\n",
    "    solid = 4 * (((s/2).tan() * (s0/2).tan() * (s1/2).tan() * (s2/2).tan()).abs() + eps).sqrt().arctan()    \n",
    "    signed_solid = solid * sign  # n_points, n_faces\n",
    "\n",
    "    winding = signed_solid.sum(dim=-1) / (4 * torch.pi)  # n_points\n",
    "    \n",
    "\n",
    "    return winding\n",
    "\n",
    "# ---------------- mesh to SDF ---------------- #\n",
    "def compute_sdf(verts, faces, points):\n",
    "\n",
    "    # Step 1: Flatten the points to shape (N, 3), where N = H * W\n",
    "    original_shape = points.shape[:-1]  # Save the original shape (H, W)\n",
    "    points_flat    = points.view(-1, 3)    # Flatten to (N, 3)    \n",
    "    verts_packed   = verts.unsqueeze(0)  # Add a batch dimension (1, V, 3)\n",
    "    \n",
    "    # Step 2: Find the closest vertex on the mesh to each point in `points`\n",
    "    dists, idx, _ = knn_points(points_flat.unsqueeze(0), verts_packed, K=1)  # (1, N, 1)\n",
    "    \n",
    "    # Step 3: Compute the distance from the query point to the closest point on the mesh\n",
    "    signed_distances = torch.sqrt(dists).squeeze(0).squeeze(-1)  # (N,)\n",
    "    \n",
    "    # Step 5: Reshape the sdf_values back to the original grid shape (H, W)\n",
    "    sdf_values = signed_distances.view(*original_shape).unsqueeze(-1)  # Add the last dimension to get (H, W, 1)\n",
    "    \n",
    "    winding = winding_number(points_flat.to(device),verts.to(device),faces.to(device))\n",
    "    \n",
    "    signs = torch.where(winding > 0.5, -1.0, 1.0)\n",
    "    \n",
    "    return sdf_values * signs.view(*original_shape).unsqueeze(-1)\n",
    "\n",
    "\n",
    "def mesh_sdf_wrapper(verts, faces):\n",
    "    def sdf(p):\n",
    "        # Use the compute_sdf function from before, which takes `verts` and `faces`\n",
    "        return compute_sdf(verts, faces, p)\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- test ---------------- #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SDF\n",
    "signed_distance_functions = sdf.translation(sdf.sphere(0.5), torch.tensor([0.0, 0.0, 0.0], device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Grid\n",
    "x_positions = torch.tensor([0., 0.2, 0. , 0.], device=device).float()\n",
    "y_positions = torch.tensor([0.5, 0., 0. , 0.], device=device).float()\n",
    "z_positions = torch.tensor([0., 0., 0.6 , 0.], device=device).float()\n",
    "\n",
    "ray_positions = torch.stack((x_positions, y_positions, z_positions), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "signed_distance_functions(ray_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render (debug)\n",
    "image = render(signed_distance_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the tensor to the range [0, 255]\n",
    "tensor = (image * 255).byte()  # Convert to byte (uint8)\n",
    "\n",
    "# Convert to NumPy array\n",
    "np_array = tensor.cpu().numpy()\n",
    "\n",
    "# Convert to a PIL image\n",
    "image = Image.fromarray(np_array)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts, faces = load_target('../data/sphere.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_sdf = mesh_sdf_wrapper(verts.to(device), faces.to(device))  # Create the mesh SDF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "mesh_sdf(ray_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render (debug)\n",
    "image_mesh = render(mesh_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the tensor to the range [0, 255]\n",
    "tensor = (image_mesh * 255).byte()  # Convert to byte (uint8)\n",
    "\n",
    "# Convert to NumPy array\n",
    "np_array = tensor.cpu().numpy()\n",
    "\n",
    "# Convert to a PIL image\n",
    "image_mesh = Image.fromarray(np_array)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(image_mesh)\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.plot(verts.numpy(), faces.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
