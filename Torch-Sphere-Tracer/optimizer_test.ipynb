{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import renderers\n",
    "import sdf\n",
    "import csg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- load target ---------------- #\n",
    "from pytorch3d.io import load_ply\n",
    "from pytorch3d.structures import Meshes\n",
    "import meshplot as mp\n",
    "\n",
    "def load_target(path):\n",
    "    # Load the target mesh\n",
    "    verts, faces = load_ply(path)\n",
    "\n",
    "    # Convert vertices to a tensor if not already\n",
    "    if not isinstance(verts, torch.Tensor):\n",
    "        verts = torch.tensor(verts, dtype=torch.float32)\n",
    "\n",
    "    # Step 1: Compute the bounding box (min/max coordinates)\n",
    "    min_coords = verts.min(dim=0)[0]\n",
    "    max_coords = verts.max(dim=0)[0]\n",
    "\n",
    "    # Step 2: Compute the center of the bounding box\n",
    "    center = (min_coords + max_coords) / 2.0\n",
    "\n",
    "    # Step 3: Center the object to the origin\n",
    "    verts_centered = verts - center\n",
    "\n",
    "    # Step 4: Compute the scale factor to fit within the unit cube\n",
    "    scale_factor = 1.0 / (max_coords - min_coords).max()\n",
    "\n",
    "    # Step 5: Scale the object to fit the unit cube\n",
    "    verts_scaled = verts_centered * scale_factor\n",
    "\n",
    "    # Step 6: Translate the object to the first octant (shift so all coordinates are positive)\n",
    "    min_coords_after_scaling = verts_scaled.min(dim=0)[0]\n",
    "    verts_final = verts_scaled - min_coords_after_scaling\n",
    "\n",
    "    # Now `mesh` is centered and scaled to fit in the first octant cube\n",
    "    return verts_final, faces\n",
    "\n",
    "from pytorch3d.ops import knn_points\n",
    "\n",
    "def multi_indexing(index: torch.Tensor, shape: torch.Size, dim=-2):\n",
    "    shape = list(shape)\n",
    "    back_pad = len(shape) - index.ndim\n",
    "    for _ in range(back_pad):\n",
    "        index = index.unsqueeze(-1)\n",
    "    expand_shape = shape\n",
    "    expand_shape[dim] = -1\n",
    "    return index.expand(*expand_shape)\n",
    "\n",
    "\n",
    "def multi_gather(values: torch.Tensor, index: torch.Tensor, dim=-2):\n",
    "    # take care of batch dimension of, and acts like a linear indexing in the target dimention\n",
    "    # we assume that the index's last dimension is the dimension to be indexed on\n",
    "    return values.gather(dim, multi_indexing(index, values.shape, dim))\n",
    "\n",
    "\n",
    "def winding_number(pts: torch.Tensor, verts: torch.Tensor, faces: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Parallel implementation of the Generalized Winding Number of points on the mesh\n",
    "    O(n_points * n_faces) memory usage, parallelized execution\n",
    "\n",
    "    1. Project tris onto the unit sphere around every points\n",
    "    2. Compute the signed solid angle of the each triangle for each point\n",
    "    3. Sum the solid angle of each triangle\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pts    : torch.Tensor, (n_points, 3)\n",
    "    verts  : torch.Tensor, (n_verts, 3)\n",
    "    faces  : torch.Tensor, (n_faces, 3)\n",
    "\n",
    "    This implementation is also able to take a/multiple batch dimension\n",
    "    \"\"\"\n",
    "    # projection onto unit sphere: verts implementation gives a little bit more performance\n",
    "    uv = verts[..., None, :, :] - pts[..., :, None, :]  # n_points, n_verts, 3\n",
    "    uv = uv / uv.norm(dim=-1, keepdim=True)  # n_points, n_verts, 3\n",
    "\n",
    "    # gather from the computed vertices (will result in a copy for sure)\n",
    "    expanded_faces = faces[..., None, :, :].expand(*faces.shape[:-2], pts.shape[-2], *faces.shape[-2:])  # n_points, n_faces, 3\n",
    "\n",
    "    u0 = multi_gather(uv, expanded_faces[..., 0])  # n, f, 3\n",
    "    u1 = multi_gather(uv, expanded_faces[..., 1])  # n, f, 3\n",
    "    u2 = multi_gather(uv, expanded_faces[..., 2])  # n, f, 3\n",
    "\n",
    "    e0 = u1 - u0  # n, f, 3\n",
    "    e1 = u2 - u1  # n, f, 3\n",
    "    del u1\n",
    "\n",
    "    # compute solid angle signs\n",
    "    sign = (torch.cross(e0, e1, dim=-1) * u2).sum(dim=-1).sign()\n",
    "\n",
    "    e2 = u0 - u2\n",
    "    del u0, u2\n",
    "\n",
    "    l0 = e0.norm(dim=-1)\n",
    "    del e0\n",
    "\n",
    "    l1 = e1.norm(dim=-1)\n",
    "    del e1\n",
    "\n",
    "    l2 = e2.norm(dim=-1)\n",
    "    del e2\n",
    "\n",
    "    # compute edge lengths: pure triangle\n",
    "    l = torch.stack([l0, l1, l2], dim=-1)  # n_points, n_faces, 3\n",
    "\n",
    "    # compute spherical edge lengths\n",
    "    l = 2 * (l/2).arcsin()  # n_points, n_faces, 3\n",
    "\n",
    "    # compute solid angle: preparing: n_points, n_faces\n",
    "    s = l.sum(dim=-1) / 2\n",
    "    s0 = s - l[..., 0]\n",
    "    s1 = s - l[..., 1]\n",
    "    s2 = s - l[..., 2]\n",
    "\n",
    "    # compute solid angle: and generalized winding number: n_points, n_faces\n",
    "    eps = 1e-10  # NOTE: will cause nan if not bigger than 1e-10\n",
    "    solid = 4 * (((s/2).tan() * (s0/2).tan() * (s1/2).tan() * (s2/2).tan()).abs() + eps).sqrt().arctan()    \n",
    "    signed_solid = solid * sign  # n_points, n_faces\n",
    "\n",
    "    winding = signed_solid.sum(dim=-1) / (4 * torch.pi)  # n_points    \n",
    "\n",
    "    return winding\n",
    "\n",
    "# ---------------- mesh to SDF ---------------- #\n",
    "def compute_sdf(verts, faces, points):\n",
    "\n",
    "    # Step 1: Flatten the points to shape (N, 3), where N = H * W\n",
    "    original_shape = points.shape[:-1]  # Save the original shape (H, W)\n",
    "    points_flat    = points.view(-1, 3)    # Flatten to (N, 3)    \n",
    "    verts_packed   = verts.unsqueeze(0)  # Add a batch dimension (1, V, 3)\n",
    "    \n",
    "    # Step 2: Find the closest vertex on the mesh to each point in `points`\n",
    "    dists, idx, _ = knn_points(points_flat.unsqueeze(0), verts_packed, K=1)  # (1, N, 1)\n",
    "    \n",
    "    # Step 3: Compute the distance from the query point to the closest point on the mesh\n",
    "    signed_distances = torch.sqrt(dists).squeeze(0).squeeze(-1)  # (N,)\n",
    "    \n",
    "    # Step 5: Reshape the sdf_values back to the original grid shape (H, W)\n",
    "    sdf_values = signed_distances.view(*original_shape).unsqueeze(-1)  # Add the last dimension to get (H, W, 1)\n",
    "    \n",
    "    winding = winding_number(points_flat.to(device),verts.to(device),faces.to(device))\n",
    "    \n",
    "    signs = torch.where(winding > 0.5, -1.0, 1.0)\n",
    "    \n",
    "    return sdf_values * signs.view(*original_shape).unsqueeze(-1)\n",
    "\n",
    "\n",
    "def mesh_sdf_wrapper(verts, faces):\n",
    "    def sdf(p):\n",
    "        # Use the compute_sdf function from before, which takes `verts` and `faces`\n",
    "        return compute_sdf(verts, faces, p)\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target\n",
    "verts, faces = load_target('../data/sphere.ply')\n",
    "mesh_sdf     = mesh_sdf_wrapper(verts.to(device), faces.to(device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize the tensors\n",
    "tensor_1 = torch.randn(1, requires_grad=True, device=device)  # Tensor of size 1\n",
    "tensor_3 = torch.randn(3, requires_grad=True, device=device)  # Tensor of size 3\n",
    "\n",
    "\n",
    "# Define an optimizer to optimize both tensors\n",
    "optimizer = optim.SGD([tensor_1,tensor_3], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples per axis (you can adjust this)\n",
    "n_samples = 10\n",
    "\n",
    "# Generate evenly spaced points for x, y, z in the range [0, 1]\n",
    "x = torch.linspace(0, 1, n_samples)\n",
    "y = torch.linspace(0, 1, n_samples)\n",
    "z = torch.linspace(0, 1, n_samples)\n",
    "\n",
    "# Create a meshgrid for x, y, z\n",
    "x_grid, y_grid, z_grid = torch.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "# Stack the grid to form the final positions\n",
    "grid_positions = torch.stack((x_grid, y_grid, z_grid), dim=-1).reshape(-1, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sdf = mesh_sdf(grid_positions).to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100000):  # Run for 100 iterations\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "    # Evaluate\n",
    "    current_sdf = sdf.translation(sdf.sphere(tensor_1), tensor_3)(grid_positions).to(device)\n",
    "    \n",
    "    # Loss: simple mean squared error between tensor and target\n",
    "    loss_1 = torch.nn.functional.mse_loss(current_sdf, target_sdf)\n",
    "    \n",
    "    # Total loss (you can weight them differently if needed)\n",
    "    total_loss = loss_1\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss and tensor values every 10 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}: Loss = {total_loss.item()}')\n",
    "        print(f'Tensor 1: {tensor_1.data}')\n",
    "        print(f'Tensor 3: {tensor_3.data}')\n",
    "\n",
    "print(\"Optimization completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sdf\n",
    "sphere = sdf.translation(sdf.sphere(1.5), torch.tensor([10.0, -10.0, 10.0], device=device))\n",
    "eval_sdf = sphere(grid_positions)\n",
    "eval_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(eval_mesh-eval_sdf).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
